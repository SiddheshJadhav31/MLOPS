{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Trips & Travel.Com\" company wants to enable and establish a viable business model to expand the customer base. One of the ways to expand the customer base is to introduce a new offering of packages. Currently, there are 5 types of packages the company is offering - Basic, Standard, Deluxe, Super Deluxe, King. Looking at the data of the last year, we observed that 18% of the customers purchased the packages. However, the marketing cost was quite high because customers were contacted at random without looking at the available information. The company is now planning to launch a new product i.e. Wellness Tourism Package. Wellness Tourism is defined as Travel that allows the traveler to maintain, enhance or kick-start a healthy lifestyle, and support or increase one's sense of well-being. However, this time company wants to harness the available data of existing and potential customers to make the marketing expenditure more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>ProdTaken</th>\n",
       "      <th>Age</th>\n",
       "      <th>TypeofContact</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NumberOfPersonVisiting</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>ProductPitched</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>Passport</th>\n",
       "      <th>PitchSatisfactionScore</th>\n",
       "      <th>OwnCar</th>\n",
       "      <th>NumberOfChildrenVisiting</th>\n",
       "      <th>Designation</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Free Lancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>18468.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  ProdTaken   Age    TypeofContact  CityTier  DurationOfPitch  \\\n",
       "0      200000          1  41.0     Self Enquiry         3              6.0   \n",
       "1      200001          0  49.0  Company Invited         1             14.0   \n",
       "2      200002          1  37.0     Self Enquiry         1              8.0   \n",
       "3      200003          0  33.0  Company Invited         1              9.0   \n",
       "4      200004          0   NaN     Self Enquiry         1              8.0   \n",
       "\n",
       "       Occupation  Gender  NumberOfPersonVisiting  NumberOfFollowups  \\\n",
       "0        Salaried  Female                       3                3.0   \n",
       "1        Salaried    Male                       3                4.0   \n",
       "2     Free Lancer    Male                       3                4.0   \n",
       "3        Salaried  Female                       2                3.0   \n",
       "4  Small Business    Male                       2                3.0   \n",
       "\n",
       "  ProductPitched  PreferredPropertyStar MaritalStatus  NumberOfTrips  \\\n",
       "0         Deluxe                    3.0        Single            1.0   \n",
       "1         Deluxe                    4.0      Divorced            2.0   \n",
       "2          Basic                    3.0        Single            7.0   \n",
       "3          Basic                    3.0      Divorced            2.0   \n",
       "4          Basic                    4.0      Divorced            1.0   \n",
       "\n",
       "   Passport  PitchSatisfactionScore  OwnCar  NumberOfChildrenVisiting  \\\n",
       "0         1                       2       1                       0.0   \n",
       "1         0                       3       1                       2.0   \n",
       "2         1                       3       0                       0.0   \n",
       "3         1                       5       1                       1.0   \n",
       "4         0                       5       1                       0.0   \n",
       "\n",
       "  Designation  MonthlyIncome  \n",
       "0     Manager        20993.0  \n",
       "1     Manager        20130.0  \n",
       "2   Executive        17090.0  \n",
       "3   Executive        17909.0  \n",
       "4   Executive        18468.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Travel.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerID                    0\n",
       "ProdTaken                     0\n",
       "Age                         226\n",
       "TypeofContact                25\n",
       "CityTier                      0\n",
       "DurationOfPitch             251\n",
       "Occupation                    0\n",
       "Gender                        0\n",
       "NumberOfPersonVisiting        0\n",
       "NumberOfFollowups            45\n",
       "ProductPitched                0\n",
       "PreferredPropertyStar        26\n",
       "MaritalStatus                 0\n",
       "NumberOfTrips               140\n",
       "Passport                      0\n",
       "PitchSatisfactionScore        0\n",
       "OwnCar                        0\n",
       "NumberOfChildrenVisiting     66\n",
       "Designation                   0\n",
       "MonthlyIncome               233\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "Male       2916\n",
       "Female     1817\n",
       "Fe Male     155\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaritalStatus\n",
       "Married      2340\n",
       "Divorced      950\n",
       "Single        916\n",
       "Unmarried     682\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MaritalStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TypeofContact\n",
       "Self Enquiry       3444\n",
       "Company Invited    1419\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TypeofContact'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'] = df['Gender'].replace('Fe Male','Female')\n",
    "df['MaritalStatus'] = df['MaritalStatus'].replace('Single','Unmarried')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "Male      2916\n",
       "Female    1972\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaritalStatus\n",
       "Married      2340\n",
       "Unmarried    1598\n",
       "Divorced      950\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MaritalStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age 4.62357 % missing values\n",
      "TypeofContact 0.51146 % missing values\n",
      "DurationOfPitch 5.13502 % missing values\n",
      "NumberOfFollowups 0.92062 % missing values\n",
      "PreferredPropertyStar 0.53191 % missing values\n",
      "NumberOfTrips 2.86416 % missing values\n",
      "NumberOfChildrenVisiting 1.35025 % missing values\n",
      "MonthlyIncome 4.76678 % missing values\n"
     ]
    }
   ],
   "source": [
    "## Missing Values: \n",
    "features_na = [features for features in df.columns if df[features].isnull().sum() >= 1]\n",
    "for features in features_na:\n",
    "    print(features, np.round(df[features].isnull().mean()*100,5), \"% missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>NumberOfChildrenVisiting</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4662.000000</td>\n",
       "      <td>4637.000000</td>\n",
       "      <td>4843.000000</td>\n",
       "      <td>4862.000000</td>\n",
       "      <td>4748.000000</td>\n",
       "      <td>4822.000000</td>\n",
       "      <td>4655.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.622265</td>\n",
       "      <td>15.490835</td>\n",
       "      <td>3.708445</td>\n",
       "      <td>3.581037</td>\n",
       "      <td>3.236521</td>\n",
       "      <td>1.187267</td>\n",
       "      <td>23619.853491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.316387</td>\n",
       "      <td>8.519643</td>\n",
       "      <td>1.002509</td>\n",
       "      <td>0.798009</td>\n",
       "      <td>1.849019</td>\n",
       "      <td>0.857861</td>\n",
       "      <td>5380.698361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20346.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22347.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>25571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>98678.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age  DurationOfPitch  NumberOfFollowups  PreferredPropertyStar  \\\n",
       "count  4662.000000      4637.000000        4843.000000            4862.000000   \n",
       "mean     37.622265        15.490835           3.708445               3.581037   \n",
       "std       9.316387         8.519643           1.002509               0.798009   \n",
       "min      18.000000         5.000000           1.000000               3.000000   \n",
       "25%      31.000000         9.000000           3.000000               3.000000   \n",
       "50%      36.000000        13.000000           4.000000               3.000000   \n",
       "75%      44.000000        20.000000           4.000000               4.000000   \n",
       "max      61.000000       127.000000           6.000000               5.000000   \n",
       "\n",
       "       NumberOfTrips  NumberOfChildrenVisiting  MonthlyIncome  \n",
       "count    4748.000000               4822.000000    4655.000000  \n",
       "mean        3.236521                  1.187267   23619.853491  \n",
       "std         1.849019                  0.857861    5380.698361  \n",
       "min         1.000000                  0.000000    1000.000000  \n",
       "25%         2.000000                  1.000000   20346.000000  \n",
       "50%         3.000000                  1.000000   22347.000000  \n",
       "75%         4.000000                  2.000000   25571.000000  \n",
       "max        22.000000                  3.000000   98678.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[features_na].select_dtypes(exclude='object').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets impute the null values: with median which have numbers and rest with mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k4/pr25ktkj0zs4hh3xq7cy_j800000gn/T/ipykernel_4681/3250460501.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.Age.fillna(df.Age.median(), inplace= True)\n"
     ]
    }
   ],
   "source": [
    "df.Age.fillna(df.Age.median(), inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k4/pr25ktkj0zs4hh3xq7cy_j800000gn/T/ipykernel_4681/1432991057.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.TypeofContact.fillna(df.TypeofContact.mode()[0],inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df.TypeofContact.fillna(df.TypeofContact.mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k4/pr25ktkj0zs4hh3xq7cy_j800000gn/T/ipykernel_4681/3607697025.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.DurationOfPitch.fillna(df.DurationOfPitch.median(), inplace= True)\n"
     ]
    }
   ],
   "source": [
    "df.DurationOfPitch.fillna(df.DurationOfPitch.median(), inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k4/pr25ktkj0zs4hh3xq7cy_j800000gn/T/ipykernel_4681/3665001522.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.PreferredPropertyStar.fillna(df.PreferredPropertyStar.median(), inplace= True)\n",
      "/var/folders/k4/pr25ktkj0zs4hh3xq7cy_j800000gn/T/ipykernel_4681/3665001522.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.NumberOfTrips.fillna(df.NumberOfTrips.median(), inplace= True)\n",
      "/var/folders/k4/pr25ktkj0zs4hh3xq7cy_j800000gn/T/ipykernel_4681/3665001522.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.NumberOfChildrenVisiting.fillna(df.NumberOfChildrenVisiting.median(), inplace= True)\n",
      "/var/folders/k4/pr25ktkj0zs4hh3xq7cy_j800000gn/T/ipykernel_4681/3665001522.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.MonthlyIncome.fillna(df.MonthlyIncome.median(), inplace= True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.PreferredPropertyStar.fillna(df.PreferredPropertyStar.median(), inplace= True)\n",
    "df.NumberOfTrips.fillna(df.NumberOfTrips.median(), inplace= True)\n",
    "df.NumberOfChildrenVisiting.fillna(df.NumberOfChildrenVisiting.median(), inplace= True)\n",
    "df.MonthlyIncome.fillna(df.MonthlyIncome.median(), inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k4/pr25ktkj0zs4hh3xq7cy_j800000gn/T/ipykernel_4681/1555167373.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.NumberOfFollowups.fillna(df.NumberOfFollowups.mode()[0],inplace=True)\n",
      "/var/folders/k4/pr25ktkj0zs4hh3xq7cy_j800000gn/T/ipykernel_4681/1555167373.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.PreferredPropertyStar.fillna(df.PreferredPropertyStar.mode()[0],inplace=True)\n",
      "/var/folders/k4/pr25ktkj0zs4hh3xq7cy_j800000gn/T/ipykernel_4681/1555167373.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.NumberOfChildrenVisiting.fillna(df.NumberOfChildrenVisiting.mode()[0], inplace= True)\n"
     ]
    }
   ],
   "source": [
    "df.TypeofContact.fillna(df.TypeofContact.mode()[0],inplace=True)\n",
    "df.NumberOfFollowups.fillna(df.NumberOfFollowups.mode()[0],inplace=True)\n",
    "df.PreferredPropertyStar.fillna(df.PreferredPropertyStar.mode()[0],inplace=True)\n",
    "df.NumberOfChildrenVisiting.fillna(df.NumberOfChildrenVisiting.mode()[0], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>ProdTaken</th>\n",
       "      <th>Age</th>\n",
       "      <th>TypeofContact</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NumberOfPersonVisiting</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>ProductPitched</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>Passport</th>\n",
       "      <th>PitchSatisfactionScore</th>\n",
       "      <th>OwnCar</th>\n",
       "      <th>NumberOfChildrenVisiting</th>\n",
       "      <th>Designation</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Free Lancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>18468.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  ProdTaken   Age    TypeofContact  CityTier  DurationOfPitch  \\\n",
       "0      200000          1  41.0     Self Enquiry         3              6.0   \n",
       "1      200001          0  49.0  Company Invited         1             14.0   \n",
       "2      200002          1  37.0     Self Enquiry         1              8.0   \n",
       "3      200003          0  33.0  Company Invited         1              9.0   \n",
       "4      200004          0  36.0     Self Enquiry         1              8.0   \n",
       "\n",
       "       Occupation  Gender  NumberOfPersonVisiting  NumberOfFollowups  \\\n",
       "0        Salaried  Female                       3                3.0   \n",
       "1        Salaried    Male                       3                4.0   \n",
       "2     Free Lancer    Male                       3                4.0   \n",
       "3        Salaried  Female                       2                3.0   \n",
       "4  Small Business    Male                       2                3.0   \n",
       "\n",
       "  ProductPitched  PreferredPropertyStar MaritalStatus  NumberOfTrips  \\\n",
       "0         Deluxe                    3.0     Unmarried            1.0   \n",
       "1         Deluxe                    4.0      Divorced            2.0   \n",
       "2          Basic                    3.0     Unmarried            7.0   \n",
       "3          Basic                    3.0      Divorced            2.0   \n",
       "4          Basic                    4.0      Divorced            1.0   \n",
       "\n",
       "   Passport  PitchSatisfactionScore  OwnCar  NumberOfChildrenVisiting  \\\n",
       "0         1                       2       1                       0.0   \n",
       "1         0                       3       1                       2.0   \n",
       "2         1                       3       0                       0.0   \n",
       "3         1                       5       1                       1.0   \n",
       "4         0                       5       1                       0.0   \n",
       "\n",
       "  Designation  MonthlyIncome  \n",
       "0     Manager        20993.0  \n",
       "1     Manager        20130.0  \n",
       "2   Executive        17090.0  \n",
       "3   Executive        17909.0  \n",
       "4   Executive        18468.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"CustomerID\",inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProdTaken                   0\n",
       "Age                         0\n",
       "TypeofContact               0\n",
       "CityTier                    0\n",
       "DurationOfPitch             0\n",
       "Occupation                  0\n",
       "Gender                      0\n",
       "NumberOfPersonVisiting      0\n",
       "NumberOfFollowups           0\n",
       "ProductPitched              0\n",
       "PreferredPropertyStar       0\n",
       "MaritalStatus               0\n",
       "NumberOfTrips               0\n",
       "Passport                    0\n",
       "PitchSatisfactionScore      0\n",
       "OwnCar                      0\n",
       "NumberOfChildrenVisiting    0\n",
       "Designation                 0\n",
       "MonthlyIncome               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalVisting'] = df['NumberOfChildrenVisiting']+df['NumberOfPersonVisiting']\n",
    "df.drop(columns=['NumberOfChildrenVisiting','NumberOfPersonVisiting'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 12 ##Number of non Object features\n",
    "cat_features = 6 #Number of Object features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "6\n",
      "9\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "num_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "cat_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "discrete_features = [feature for feature in num_features if len(df[feature].unique()) <= 25 ]\n",
    "continuous_features = [feature for feature in num_features if feature not in discrete_features ]\n",
    "print(len(num_features))\n",
    "print(len(cat_features))\n",
    "print(len(discrete_features))\n",
    "print(len(continuous_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['ProdTaken'], axis = 1)\n",
    "y = df['ProdTaken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProdTaken\n",
       "0    3968\n",
       "1     920\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3910, 17), (978, 17))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "X_train.shape , X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = X.select_dtypes(include=\"object\").columns\n",
    "num_features = X.select_dtypes(exclude='object').columns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('OneHotEncoder', oh_transformer, cat_features),\n",
    "        ('StandardScaler',numeric_transformer, num_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay,precision_score,recall_score,f1_score,roc_auc_score,roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Random Forest\" : RandomForestClassifier(),\n",
    "    \"Decision Tree\" : DecisionTreeClassifier(),\n",
    "    \"Adaboost \" : AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "For training data: \n",
      "-------------------------------\n",
      "Accuracy : 1.0\n",
      "Precision: 1.0\n",
      "F1 score:  1.0\n",
      "Recall:  1.0\n",
      "ROCAUC : 1.0\n",
      "                      \n",
      "For test data: \n",
      "-------------------------------\n",
      "Accuracy : 0.9274028629856851\n",
      "Precision: 0.9615384615384616\n",
      "F1 score:  0.778816199376947\n",
      "Recall:  0.6544502617801047\n",
      "ROCAUC : 0.9418541364296082\n",
      "-------------------------------\n",
      "Decision Tree\n",
      "For training data: \n",
      "-------------------------------\n",
      "Accuracy : 1.0\n",
      "Precision: 1.0\n",
      "F1 score:  1.0\n",
      "Recall:  1.0\n",
      "ROCAUC : 1.0\n",
      "                      \n",
      "For test data: \n",
      "-------------------------------\n",
      "Accuracy : 0.9202453987730062\n",
      "Precision: 0.8021390374331551\n",
      "F1 score:  0.7936507936507936\n",
      "Recall:  0.7853403141361257\n",
      "ROCAUC : 0.8751529574017862\n",
      "-------------------------------\n",
      "Adaboost \n",
      "For training data: \n",
      "-------------------------------\n",
      "Accuracy : 0.8565217391304348\n",
      "Precision: 0.7307692307692307\n",
      "F1 score:  0.4867337602927722\n",
      "Recall:  0.36488340192043894\n",
      "ROCAUC : 0.8000997874094321\n",
      "                      \n",
      "For test data: \n",
      "-------------------------------\n",
      "Accuracy : 0.8353783231083844\n",
      "Precision: 0.6630434782608695\n",
      "F1 score:  0.43109540636042404\n",
      "Recall:  0.3193717277486911\n",
      "ROCAUC : 0.7581583079791933\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    model_tr_acc = accuracy_score(y_train,y_train_pred)\n",
    "    model_tr_f1 = f1_score(y_train,y_train_pred)\n",
    "    model_tr_prec = precision_score(y_train,y_train_pred)\n",
    "    model_tr_recall = recall_score(y_train, y_train_pred)\n",
    "    model_tr_roc = roc_auc_score(y_train_pred,y_train)\n",
    "\n",
    "    model_ts_acc = accuracy_score(y_test, y_test_pred)\n",
    "    model_ts_f1 = f1_score(y_test, y_test_pred)\n",
    "    model_ts_prec = precision_score(y_test, y_test_pred)\n",
    "    model_ts_recall = recall_score(y_test, y_test_pred)\n",
    "    model_ts_roc = roc_auc_score(y_test_pred,y_test)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "\n",
    "    print(\"For training data: \")\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Accuracy :\",model_tr_acc)\n",
    "    print(\"Precision:\",model_tr_prec)\n",
    "    print(\"F1 score: \",model_tr_f1)\n",
    "    print(\"Recall: \",model_tr_recall)\n",
    "    print(\"ROCAUC :\",model_tr_roc)\n",
    "\n",
    "    print(\"                      \")\n",
    "\n",
    "    print(\"For test data: \")\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Accuracy :\",model_ts_acc)\n",
    "    print(\"Precision:\",model_ts_prec)\n",
    "    print(\"F1 score: \",model_ts_f1)\n",
    "    print(\"Recall: \",model_ts_recall)\n",
    "    print(\"ROCAUC :\",model_ts_roc)\n",
    "\n",
    "    print(\"-------------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Training for random forest as its better model for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    \"max_depth\" : [5,8,15,10],\n",
    "    \"max_features\" : [5,7,'auto',8],\n",
    "    \"min_samples_split\": [2,8,15,20],\n",
    "    'n_estimators': [100,200,500,1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': [5, 8, 15, 10],\n",
       " 'max_features': [5, 7, 'auto', 8],\n",
       " 'min_samples_split': [2, 8, 15, 20],\n",
       " 'n_estimators': [100, 200, 500, 1000]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_params = {\n",
    "    \"n_estimators\" : [50,60,70,90,100],\n",
    "    \"algorithm\" : ['SAMME','SAMME.R'],\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomcv_models = [\n",
    "    (\"RF\",RandomForestClassifier(),rf_params),\n",
    "    (\"AB\",AdaBoostClassifier(),adaboost_params)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RF',\n",
       "  RandomForestClassifier(),\n",
       "  {'max_depth': [5, 8, 15, 10],\n",
       "   'max_features': [5, 7, 'auto', 8],\n",
       "   'min_samples_split': [2, 8, 15, 20],\n",
       "   'n_estimators': [100, 200, 500, 1000]}),\n",
       " ('AB',\n",
       "  AdaBoostClassifier(),\n",
       "  {'n_estimators': [50, 60, 70, 90, 100], 'algorithm': ['SAMME', 'SAMME.R']})]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomcv_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=8, n_estimators=1000; total time=   3.7s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=8, n_estimators=1000; total time=   3.6s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=8, n_estimators=1000; total time=   3.7s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=15, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=15, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=15, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=15, n_estimators=1000; total time=   3.1s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=15, n_estimators=1000; total time=   3.1s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=15, n_estimators=1000; total time=   3.2s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=8, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=8, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=8, n_estimators=500; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=2, n_estimators=1000; total time=   3.3s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=2, n_estimators=1000; total time=   3.3s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=2, n_estimators=1000; total time=   3.4s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=20, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=20, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=20, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=2, n_estimators=1000; total time=   2.7s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=2, n_estimators=1000; total time=   2.8s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=2, n_estimators=1000; total time=   2.8s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=15, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=15, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=15, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=15, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=2, n_estimators=500; total time=   1.5s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=2, n_estimators=500; total time=   1.6s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=2, n_estimators=500; total time=   1.5s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=15, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=15, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=15, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=2, n_estimators=500; total time=   1.4s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=2, n_estimators=500; total time=   1.4s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=2, n_estimators=500; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=15, n_estimators=1000; total time=   2.9s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=15, n_estimators=1000; total time=   2.9s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=15, n_estimators=1000; total time=   3.1s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=15, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=15, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=15, n_estimators=1000; total time=   2.6s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=15, n_estimators=1000; total time=   2.6s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=15, n_estimators=1000; total time=   2.6s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=8, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=8, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=8, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=15, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=15, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=15, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=8, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=8, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=8, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=15, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=15, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=15, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=20, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=20, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=20, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=20, n_estimators=500; total time=   1.7s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=20, n_estimators=500; total time=   1.5s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=20, n_estimators=500; total time=   1.5s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=2, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=2, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=2, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=8, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=8, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=8, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=15, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=15, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=15, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=20, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=20, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=20, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=20, n_estimators=500; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=20, n_estimators=500; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=20, n_estimators=500; total time=   1.5s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=8, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=8, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=8, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=20, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=20, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=20, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=20, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=20, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=20, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=2, n_estimators=1000; total time=   2.1s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=2, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=2, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=20, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=20, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=20, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=2, n_estimators=500; total time=   1.7s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=2, n_estimators=500; total time=   1.7s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=2, n_estimators=500; total time=   1.7s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=20, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=20, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=20, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=20, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=20, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=20, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=20, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=20, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=20, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=8, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=8, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=8, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=15, n_estimators=1000; total time=   2.3s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=15, n_estimators=1000; total time=   2.3s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=15, n_estimators=1000; total time=   2.4s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=2, n_estimators=1000; total time=   2.9s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=2, n_estimators=1000; total time=   2.9s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=2, n_estimators=1000; total time=   2.9s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=2, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=2, n_estimators=1000; total time=   1.8s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=2, n_estimators=1000; total time=   1.8s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=20, n_estimators=1000; total time=   3.1s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=20, n_estimators=1000; total time=   3.1s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=20, n_estimators=1000; total time=   3.1s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=20, n_estimators=500; total time=   1.6s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=20, n_estimators=500; total time=   1.6s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=20, n_estimators=500; total time=   1.6s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=8, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=20, n_estimators=1000; total time=   2.8s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=20, n_estimators=1000; total time=   2.9s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=20, n_estimators=1000; total time=   2.9s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=20, n_estimators=1000; total time=   2.2s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=20, n_estimators=1000; total time=   2.2s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=20, n_estimators=1000; total time=   2.2s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=8, n_estimators=500; total time=   1.6s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=8, n_estimators=500; total time=   1.6s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=8, n_estimators=500; total time=   1.7s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=20, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=20, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=20, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=8, n_estimators=1000; total time=   2.2s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=8, n_estimators=1000; total time=   2.1s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=8, n_estimators=1000; total time=   2.2s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=2, n_estimators=1000; total time=   3.0s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=2, n_estimators=1000; total time=   2.9s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=2, n_estimators=1000; total time=   3.0s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=15, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=15, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=15, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=20, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=20, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=20, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=8, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=8, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=8, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=15, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=15, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=15, n_estimators=1000; total time=   2.1s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=15, n_estimators=1000; total time=   2.7s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=15, n_estimators=1000; total time=   2.7s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=15, n_estimators=1000; total time=   2.7s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=20, n_estimators=500; total time=   1.4s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=20, n_estimators=500; total time=   1.4s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=20, n_estimators=500; total time=   1.5s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=2, n_estimators=500; total time=   1.5s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=2, n_estimators=500; total time=   1.4s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=2, n_estimators=500; total time=   1.4s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=15, n_estimators=1000; total time=   3.4s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=15, n_estimators=1000; total time=   3.5s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=15, n_estimators=1000; total time=   3.5s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=20, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=20, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=20, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=8, n_estimators=1000; total time=   1.8s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=8, n_estimators=1000; total time=   1.8s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=8, n_estimators=1000; total time=   1.8s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=1000; total time=   2.7s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=1000; total time=   2.6s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=1000; total time=   2.6s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=8, n_estimators=200; total time=   0.7s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=8, n_estimators=200; total time=   0.7s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=8, n_estimators=200; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "66 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "66 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.8685429         nan 0.88900261        nan 0.87186738 0.86803107\n",
      " 0.88976948 0.87340132 0.87365812 0.84271215 0.86470639        nan\n",
      " 0.87289066 0.86445096 0.84322399 0.87519128        nan 0.84501394\n",
      " 0.87263504 0.87007664 0.87570233 0.86803067        nan 0.87698182\n",
      "        nan        nan 0.84117802 0.87902838 0.91509094 0.84296837\n",
      "        nan 0.85959136        nan 0.86521783 0.86828747 0.87416996\n",
      "        nan        nan        nan        nan 0.85319822 0.8432236\n",
      " 0.83529553 0.86675236 0.84475891 0.88133037 0.86649732        nan\n",
      " 0.84475812 0.84168887 0.90767236 0.84399106 0.86010281 0.8915612\n",
      " 0.85831344 0.84347942 0.86240499 0.86879853 0.85524439 0.90818498\n",
      " 0.86879872 0.83529495 0.86572888 0.88695801 0.86470776 0.84194528\n",
      " 0.88414419 0.86777525 0.86240597        nan 0.86572947 0.85217553\n",
      "        nan 0.88184161 0.8347835  0.84578121 0.89155983 0.87493585\n",
      " 0.86342807        nan 0.83580619        nan        nan 0.84373583\n",
      "        nan        nan 0.85959117 0.88312052 0.84271215 0.86445096\n",
      " 0.8624046  0.9071619         nan 0.84450211 0.87544729 0.84117782\n",
      " 0.83452768 0.85319743 0.88516609 0.88951444]\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 10 is smaller than n_iter=100. Running 10 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=60; total time=   0.1s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=60; total time=   0.1s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=60; total time=   0.1s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=70; total time=   0.2s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=70; total time=   0.2s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=70; total time=   0.2s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=90; total time=   0.2s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=90; total time=   0.2s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=90; total time=   0.2s\n",
      "[CV] END ..................algorithm=SAMME, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..................algorithm=SAMME, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..................algorithm=SAMME, n_estimators=100; total time=   0.3s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=50; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................algorithm=SAMME.R, n_estimators=50; total time=   0.1s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=50; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................algorithm=SAMME.R, n_estimators=60; total time=   0.2s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=60; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................algorithm=SAMME.R, n_estimators=60; total time=   0.2s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=70; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................algorithm=SAMME.R, n_estimators=70; total time=   0.2s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=70; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................algorithm=SAMME.R, n_estimators=90; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................algorithm=SAMME.R, n_estimators=90; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................algorithm=SAMME.R, n_estimators=90; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................algorithm=SAMME.R, n_estimators=100; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................algorithm=SAMME.R, n_estimators=100; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................algorithm=SAMME.R, n_estimators=100; total time=   0.3s\n",
      "RF {'n_estimators': 200, 'min_samples_split': 2, 'max_features': 8, 'max_depth': 15}\n",
      "AB {'n_estimators': 90, 'algorithm': 'SAMME'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model_param = {}\n",
    "for name, model,params in randomcv_models:\n",
    "    random = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions= params,\n",
    "        n_iter= 100,\n",
    "        cv = 3,\n",
    "        verbose= 2, \n",
    "        n_jobs=1\n",
    "    )\n",
    "\n",
    "    random.fit(X_train, y_train)\n",
    "    model_param[name] = random.best_params_\n",
    "\n",
    "for modelname in model_param:\n",
    "    print(modelname, model_param[modelname] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Random Forest\" : RandomForestClassifier(n_estimators= 100, min_samples_split= 2, max_features= 8, max_depth= 15),\n",
    "    \"Adaboost\" : AdaBoostClassifier(n_estimators = 90,algorithm = 'SAMME')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "For training data: \n",
      "-------------------------------\n",
      "Accuracy : 0.9987212276214834\n",
      "Precision: 1.0\n",
      "F1 score:  0.9965588437715073\n",
      "Recall:  0.9931412894375857\n",
      "ROCAUC : 0.9992153170119271\n",
      "                      \n",
      "For test data: \n",
      "-------------------------------\n",
      "Accuracy : 0.9294478527607362\n",
      "Precision: 0.9485294117647058\n",
      "F1 score:  0.7889908256880734\n",
      "Recall:  0.675392670157068\n",
      "ROCAUC : 0.9374476037445857\n",
      "-------------------------------\n",
      "Adaboost\n",
      "For training data: \n",
      "-------------------------------\n",
      "Accuracy : 0.8473145780051151\n",
      "Precision: 0.775\n",
      "F1 score:  0.38390092879256965\n",
      "Recall:  0.2551440329218107\n",
      "ROCAUC : 0.8135217983651225\n",
      "                      \n",
      "For test data: \n",
      "-------------------------------\n",
      "Accuracy : 0.83640081799591\n",
      "Precision: 0.7818181818181819\n",
      "F1 score:  0.34959349593495936\n",
      "Recall:  0.225130890052356\n",
      "ROCAUC : 0.8107357431301094\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    model_tr_acc = accuracy_score(y_train,y_train_pred)\n",
    "    model_tr_f1 = f1_score(y_train,y_train_pred)\n",
    "    model_tr_prec = precision_score(y_train,y_train_pred)\n",
    "    model_tr_recall = recall_score(y_train, y_train_pred)\n",
    "    model_tr_roc = roc_auc_score(y_train_pred,y_train)\n",
    "\n",
    "    model_ts_acc = accuracy_score(y_test, y_test_pred)\n",
    "    model_ts_f1 = f1_score(y_test, y_test_pred)\n",
    "    model_ts_prec = precision_score(y_test, y_test_pred)\n",
    "    model_ts_recall = recall_score(y_test, y_test_pred)\n",
    "    model_ts_roc = roc_auc_score(y_test_pred,y_test)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "\n",
    "    print(\"For training data: \")\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Accuracy :\",model_tr_acc)\n",
    "    print(\"Precision:\",model_tr_prec)\n",
    "    print(\"F1 score: \",model_tr_f1)\n",
    "    print(\"Recall: \",model_tr_recall)\n",
    "    print(\"ROCAUC :\",model_tr_roc)\n",
    "\n",
    "    print(\"                      \")\n",
    "\n",
    "    print(\"For test data: \")\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Accuracy :\",model_ts_acc)\n",
    "    print(\"Precision:\",model_ts_prec)\n",
    "    print(\"F1 score: \",model_ts_f1)\n",
    "    print(\"Recall: \",model_ts_recall)\n",
    "    print(\"ROCAUC :\",model_ts_roc)\n",
    "\n",
    "    print(\"-------------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
